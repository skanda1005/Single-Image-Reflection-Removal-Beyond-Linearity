{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Samsung-Prism.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY5WW2P9sqF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d6427a-507b-46f5-f80f-74532a01f3d4"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFx-HJjwvuOI"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/reflection-removal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzGJaVfWqDy-",
        "outputId": "ec674edb-51f2-4471-e701-33c7eda83418"
      },
      "source": [
        "from __future__ import division\n",
        "import os,time,cv2,scipy.io\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import argparse\n",
        "from discriminator import build_discriminator\n",
        "from psnr_ssim import * #my code\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--gpu_id\", default=\"7\", help=\"GPU id for training\")\n",
        "parser.add_argument(\"--task\", default=\"/content/drive/MyDrive/reflection-removal/pre-trained.tar/pre-trained\", help=\"path to folder containing the model\")\n",
        "parser.add_argument(\"--data\", default=\"/media/sharesto/data/SM/data/\", help=\"path to synthetic dataset\")\n",
        "parser.add_argument(\"--save_model_freq\", default=3, type=int, help=\"frequency to save model\")\n",
        "parser.add_argument(\"--is_hyper\", default=1, type=int, help=\"use hypercolumn or not\")\n",
        "parser.add_argument(\"--is_training\", default=0, help=\"training or testing\")\n",
        "parser.add_argument(\"--continue_training\", default=False, action=\"store_true\", help=\"search for checkpoint in the subfolder specified by `task` argument\")\n",
        "ARGS = parser.parse_args(args=[])\n",
        "\n",
        "gpu_id = ARGS.gpu_id\n",
        "task=ARGS.task\n",
        "is_training=ARGS.is_training\n",
        "continue_training=ARGS.continue_training\n",
        "hyper=ARGS.is_hyper==1\n",
        "\n",
        "if is_training:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES']=gpu_id\n",
        "else:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES']=gpu_id\n",
        "\n",
        "print('CUDA_VISIBLE_DEVICES', gpu_id)\n",
        "\n",
        "print('is_training:', is_training)\n",
        "EPS = 1e-12\n",
        "channel = 64 # number of feature channels to build the model, set to 64\n",
        "train_syn_root=ARGS.data\n",
        "\n",
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
        "\n",
        "def build_net(ntype, nin, nwb=None, name=None):\n",
        "    if ntype == 'conv':\n",
        "        return tf.nn.relu(tf.nn.conv2d(nin, nwb[0], strides=[1, 1, 1, 1], padding='SAME', name=name) + nwb[1])\n",
        "    elif ntype == 'pool':\n",
        "        return tf.nn.avg_pool2d(nin, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "def get_weight_bias(vgg_layers, i):\n",
        "    weights = vgg_layers[i][0][0][2][0][0]\n",
        "    weights = tf.constant(weights)\n",
        "    bias = vgg_layers[i][0][0][2][0][1]\n",
        "    bias = tf.constant(np.reshape(bias, (bias.size)))\n",
        "    return weights, bias\n",
        "\n",
        "\n",
        "def lrelu(x):\n",
        "    return tf.maximum(x * 0.2, x)\n",
        "\n",
        "\n",
        "def relu(x):\n",
        "    return tf.maximum(0.0, x)\n",
        "\n",
        "\n",
        "def identity_initializer():\n",
        "    def _initializer(shape, dtype=tf.float32, partition_info=None):\n",
        "        array = np.zeros(shape, dtype=float)\n",
        "        cx, cy = shape[0] // 2, shape[1] // 2\n",
        "        for i in range(np.minimum(shape[2], shape[3])):\n",
        "            array[cx, cy, i, i] = 1\n",
        "        return tf.constant(array, dtype=dtype)\n",
        "\n",
        "    return _initializer\n",
        "\n",
        "\n",
        "def nm(x):\n",
        "    w0 = tf.Variable(1.0, name='w0')\n",
        "    w1 = tf.Variable(0.0, name='w1')\n",
        "    return w0 * x + w1 * slim.batch_norm(x)\n",
        "\n",
        "\n",
        "vgg_path = scipy.io.loadmat('/content/drive/MyDrive/reflection-removal/VGG Model/imagenet-vgg-verydeep-19.mat')\n",
        "\n",
        "print(\"[i] Loaded pre-trained vgg19 parameters\")\n",
        "\n",
        "# build VGG19 to load pre-trained parameters\n",
        "def build_vgg19(input, reuse=False):\n",
        "    with tf.compat.v1.variable_scope(\"vgg19\"):\n",
        "        if reuse:\n",
        "            tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "        net = {}\n",
        "        vgg_layers = vgg_path['layers'][0]\n",
        "        net['input'] = input - np.array([123.6800, 116.7790, 103.9390]).reshape((1, 1, 1, 3))\n",
        "        net['conv1_1'] = build_net('conv', net['input'], get_weight_bias(vgg_layers, 0), name='vgg_conv1_1')\n",
        "        net['conv1_2'] = build_net('conv', net['conv1_1'], get_weight_bias(vgg_layers, 2), name='vgg_conv1_2')\n",
        "        net['pool1'] = build_net('pool', net['conv1_2'])\n",
        "        net['conv2_1'] = build_net('conv', net['pool1'], get_weight_bias(vgg_layers, 5), name='vgg_conv2_1')\n",
        "        net['conv2_2'] = build_net('conv', net['conv2_1'], get_weight_bias(vgg_layers, 7), name='vgg_conv2_2')\n",
        "        net['pool2'] = build_net('pool', net['conv2_2'])\n",
        "        net['conv3_1'] = build_net('conv', net['pool2'], get_weight_bias(vgg_layers, 10), name='vgg_conv3_1')\n",
        "        net['conv3_2'] = build_net('conv', net['conv3_1'], get_weight_bias(vgg_layers, 12), name='vgg_conv3_2')\n",
        "        net['conv3_3'] = build_net('conv', net['conv3_2'], get_weight_bias(vgg_layers, 14), name='vgg_conv3_3')\n",
        "        net['conv3_4'] = build_net('conv', net['conv3_3'], get_weight_bias(vgg_layers, 16), name='vgg_conv3_4')\n",
        "        net['pool3'] = build_net('pool', net['conv3_4'])\n",
        "        net['conv4_1'] = build_net('conv', net['pool3'], get_weight_bias(vgg_layers, 19), name='vgg_conv4_1')\n",
        "        net['conv4_2'] = build_net('conv', net['conv4_1'], get_weight_bias(vgg_layers, 21), name='vgg_conv4_2')\n",
        "        net['conv4_3'] = build_net('conv', net['conv4_2'], get_weight_bias(vgg_layers, 23), name='vgg_conv4_3')\n",
        "        net['conv4_4'] = build_net('conv', net['conv4_3'], get_weight_bias(vgg_layers, 25), name='vgg_conv4_4')\n",
        "        net['pool4'] = build_net('pool', net['conv4_4'])\n",
        "        net['conv5_1'] = build_net('conv', net['pool4'], get_weight_bias(vgg_layers, 28), name='vgg_conv5_1')\n",
        "        net['conv5_2'] = build_net('conv', net['conv5_1'], get_weight_bias(vgg_layers, 30), name='vgg_conv5_2')\n",
        "        return net\n",
        "\n",
        "\n",
        "def build_reconnet(input): #BTnet, here in this code it is named as reconstruction net\n",
        "    if hyper:\n",
        "        print(\"[i] Reconnet: Hypercolumn ON, building hypercolumn features ... \")\n",
        "        vgg19_features=build_vgg19(input[:,:,:,0:3]*255.0)\n",
        "        for layer_id in range(1,6):\n",
        "            vgg19_f = vgg19_features['conv%d_2'%layer_id]\n",
        "            input = tf.concat([tf.image.resize_bilinear(vgg19_f,(tf.shape(input)[1],tf.shape(input)[2]))/255.0,input], axis=3)\n",
        "    else:\n",
        "        vgg19_features=build_vgg19(input[:,:,:,0:3]*255.0)\n",
        "        for layer_id in range(1,6):\n",
        "            vgg19_f = vgg19_features['conv%d_2'%layer_id]\n",
        "            input = tf.concat([tf.image.resize_bilinear(tf.zeros_like(vgg19_f),(tf.shape(input)[1],tf.shape(input)[2]))/255.0,input], axis=3)\n",
        "    net=slim.conv2d(input,channel,[1,1],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv0')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv1')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=2,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv2')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=4,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv3')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=8,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv4')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=16,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv5')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=32,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv6')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=64,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv7')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv9')\n",
        "    net=slim.conv2d(net,3,[1,1],rate=1,activation_fn=None,scope='g_conv_last') # output 6 channels --> 3 for transmission layer and 3 for reflection layer\n",
        "    return net\n",
        "\n",
        "# our reflection removal model\n",
        "def build(input):\n",
        "    if hyper:\n",
        "        print(\"[i] Hypercolumn ON, building hypercolumn features ... \")\n",
        "        vgg19_features=build_vgg19(input[:,:,:,0:3]*255.0)\n",
        "        for layer_id in range(1,6):\n",
        "            vgg19_f = vgg19_features['conv%d_2'%layer_id]\n",
        "            input = tf.concat([tf.compat.v1.image.resize_bilinear(vgg19_f,(tf.shape(input)[1],tf.shape(input)[2]))/255.0,input], axis=3)\n",
        "    else:\n",
        "        vgg19_features=build_vgg19(input[:,:,:,0:3]*255.0)\n",
        "        for layer_id in range(1,6):\n",
        "            vgg19_f = vgg19_features['conv%d_2'%layer_id]\n",
        "            input = tf.concat([tf.image.resize_bilinear(tf.zeros_like(vgg19_f),(tf.shape(input)[1],tf.shape(input)[2]))/255.0,input], axis=3)\n",
        "    net=slim.conv2d(input,channel,[1,1],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv0')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv1')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=2,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv2')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=4,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv3')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=8,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv4')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=16,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv5')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=32,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv6')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=64,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv7')\n",
        "    net=slim.conv2d(net,channel,[3,3],rate=1,activation_fn=lrelu,normalizer_fn=nm,weights_initializer=identity_initializer(),scope='g_conv9')\n",
        "    net=slim.conv2d(net,3*2,[1,1],rate=1,activation_fn=None,scope='g_conv_last') # output 6 channels --> 3 for transmission layer and 3 for reflection layer\n",
        "    return net\n",
        "\n",
        "def compute_l1_loss(input, output):\n",
        "    return tf.reduce_mean(tf.abs(input-output))\n",
        "\n",
        "def compute_percep_loss(input, output, reuse=False):\n",
        "    vgg_real=build_vgg19(output*255.0,reuse=reuse)\n",
        "    vgg_fake=build_vgg19(input*255.0,reuse=True)\n",
        "    p0=compute_l1_loss(vgg_real['input'],vgg_fake['input'])\n",
        "    p1=compute_l1_loss(vgg_real['conv1_2'],vgg_fake['conv1_2'])/2.6\n",
        "    p2=compute_l1_loss(vgg_real['conv2_2'],vgg_fake['conv2_2'])/4.8\n",
        "    p3=compute_l1_loss(vgg_real['conv3_2'],vgg_fake['conv3_2'])/3.7\n",
        "    p4=compute_l1_loss(vgg_real['conv4_2'],vgg_fake['conv4_2'])/5.6\n",
        "    p5=compute_l1_loss(vgg_real['conv5_2'],vgg_fake['conv5_2'])*10/1.5\n",
        "    return p0+p1+p2+p3+p4+p5\n",
        "\n",
        "def compute_gradient(img):\n",
        "    gradx=img[:,1:,:,:]-img[:,:-1,:,:]\n",
        "    grady=img[:,:,1:,:]-img[:,:,:-1,:]\n",
        "    return gradx,grady\n",
        "\n",
        "\n",
        "\n",
        "def prepare_data_test(test_path):\n",
        "    input_names=[]\n",
        "    for dirname in test_path:\n",
        "        for _, _, fnames in sorted(os.walk(dirname)):\n",
        "            for fname in fnames:\n",
        "                if is_image_file(fname):\n",
        "                    input_names.append(os.path.join(dirname, fname))\n",
        "    return input_names\n",
        "\n",
        "#--------------------reflection removal network ---------------------------------------------------------------------------------------------\n",
        "\n",
        "input = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "targetgR = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "targetT =tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "targetR = tf.compat.v1.placeholder(tf.float32, shape=[None, None, None, 3])\n",
        "\n",
        "# build the model\n",
        "network = build(input)\n",
        "transmission_layer, reflection_layerb4 = tf.split(network, num_or_size_splits=2, axis=3) #split network output to T, gR (reflection_layerb4 == glass reflected R, before applying BTnet)\n",
        "\n",
        "# Perceptual Loss b4 (perceptual loss of gR, before applying BTnet)\n",
        "loss_percep_rb4 = compute_percep_loss(reflection_layerb4, targetgR, reuse=True)\n",
        "\n",
        "# L1 loss on reflection image b4\n",
        "loss_l1_rb4 = compute_l1_loss(reflection_layerb4, targetgR)  # temp!! activate this line for real training SM\n",
        "\n",
        "lossb4 = loss_l1_rb4 + loss_percep_rb4 * 0.2\n",
        "\n",
        "# set up the model and define the graph : BTnet\n",
        "with tf.compat.v1.variable_scope('R_reconnet'): #R reconstruction== BT-net\n",
        "    inputgR = reflection_layerb4\n",
        "    # build the model\n",
        "    reflection_layer = build_reconnet(inputgR)\n",
        "    reflection_layer = tf.identity(reflection_layer, name=\"reflection_layer\")\n",
        "\n",
        "# Perceptual Loss\n",
        "loss_percep_t = compute_percep_loss(transmission_layer, targetT)\n",
        "loss_percep_r = compute_percep_loss(reflection_layer, targetR, reuse=True)\n",
        "loss_percep = loss_percep_t + loss_percep_r\n",
        "\n",
        "# Adversarial Loss\n",
        "with tf.variable_scope(\"discriminator\"):\n",
        "    predict_real, pred_real_dict = build_discriminator(discrim_inputs=input, discrim_targets=targetT)\n",
        "with tf.variable_scope(\"discriminator\", reuse=True):\n",
        "    predict_fake, pred_fake_dict = build_discriminator(input, transmission_layer)\n",
        "\n",
        "d_loss = (tf.reduce_mean(-(tf.math.log(predict_real + EPS) + tf.math.log(1 - predict_fake + EPS)))) * 0.5\n",
        "g_loss = tf.reduce_mean(-tf.math.log(predict_fake + EPS))\n",
        "\n",
        "loss_l1_r = compute_l1_loss(reflection_layer, targetR)\n",
        "loss_l1_t = compute_l1_loss(transmission_layer, targetT)\n",
        "\n",
        "# lossb4 == a priori loss in the paper\n",
        "loss = loss_l1_r + loss_percep * 0.2 + loss_l1_t+ lossb4\n",
        "\n",
        "train_vars = tf.compat.v1.trainable_variables()\n",
        "d_vars = [var for var in train_vars if 'discriminator' in var.name]\n",
        "g_vars = [var for var in train_vars if 'g_' in var.name]\n",
        "\n",
        "g_opt = tf.compat.v1.train.AdamOptimizer(learning_rate=0.0002).minimize(loss * 100 + g_loss,\n",
        "                                                              var_list=g_vars)  # optimizer for the generator\n",
        "d_opt = tf.compat.v1.train.AdamOptimizer(learning_rate=0.0001).minimize(d_loss,\n",
        "                                                              var_list=d_vars)  # optimizer for the discriminator\n",
        "\n",
        "#for evaluation\n",
        "def prepare_data_test(test_path, inputN):\n",
        "    input_names = []\n",
        "    for fn in os.listdir(test_path):\n",
        "        if is_image_file(fn) and inputN in fn:\n",
        "            input_names.append(os.path.join(test_path,fn))\n",
        "    return input_names\n",
        "\n",
        "\n",
        "SPnet_path = task\n",
        "print('task', task)\n",
        "savedir = '/content/drive/MyDrive/Prism-test/Results' # for testing :SAVE_directory\n",
        "\n",
        "ckpt = tf.train.get_checkpoint_state(SPnet_path)\n",
        "saver=tf.compat.v1.train.Saver(max_to_keep=110)\n",
        "# Session starts-------------------------------------------------\n",
        "sess=tf.compat.v1.Session()\n",
        "sess.run(tf.compat.v1.global_variables_initializer())\n",
        "if(is_training and not ckpt):\n",
        "    print('this code for testing, not for training')\n",
        "\n",
        "\n",
        "else:\n",
        "    if(not ckpt):\n",
        "        print('This is testing but no checkpoint. The program will be terminated')\n",
        "        exit()\n",
        "    ckpt = tf.train.get_checkpoint_state(SPnet_path)\n",
        "    saver_restore = tf.compat.v1.train.Saver([var for var in tf.compat.v1.trainable_variables()])\n",
        "    print('Separation net loaded' + ckpt.model_checkpoint_path)\n",
        "    saver_restore.restore(sess, ckpt.model_checkpoint_path)\n",
        "\n",
        "maxepoch = 140\n",
        "if is_training:\n",
        "\n",
        "    print('This code is for testing.')\n",
        "\n",
        "# To test the model on images with reflection\n",
        "else:\n",
        "    print('The testing part is executing')\n",
        "\n",
        "    modelN = SPnet_path.rsplit('/',3)[1] #model name\n",
        "    epochN = SPnet_path.rsplit('/',3)[2] #epoch N\n",
        "    outputdir = os.path.join(savedir,modelN, epochN) #output directory\n",
        "\n",
        "    #for test images---------------------------------------------------------------------------------------------\n",
        "    input_path = '/content/drive/MyDrive/Prism-test'\n",
        "    input_names =  prepare_data_test(input_path, '.jpg')\n",
        "\n",
        "    for input_path in input_names:\n",
        "        testind = os.path.splitext(os.path.basename(input_path))[0] #filename correct for directory seprated as well\n",
        "        testsetN = input_path.rsplit('/',3)[1] #testset name\n",
        "\n",
        "        if not os.path.isfile(input_path):\n",
        "            continue\n",
        "\n",
        "        img=cv2.imread(input_path)\n",
        "        input_image=np.expand_dims(np.float32(img), axis=0)/255.0\n",
        "        st=time.time()\n",
        "        fetch_list = [transmission_layer, reflection_layerb4, reflection_layer]\n",
        "        output_image_t, output_image_rb4, output_image_r=sess.run(fetch_list,feed_dict={input:input_image})\n",
        "        print(\"Test time %.3f for image %s\"%(time.time()-st, input_path))\n",
        "\n",
        "        output_image_t=np.minimum(np.maximum(output_image_t,0.0),1.0)*255.0\n",
        "        output_image_rb4=np.minimum(np.maximum(output_image_rb4,0.0),1.0)*255.0\n",
        "        output_image_r=np.minimum(np.maximum(output_image_r,0.0),1.0)*255.0\n",
        "\n",
        "        #saving the images\n",
        "        if not os.path.isdir(os.path.join(outputdir,testsetN)):\n",
        "            os.makedirs(os.path.join(outputdir,testsetN))\n",
        "            print('dir is created: %s' %os.path.join(outputdir,testsetN))\n",
        "        outputdir_fin = os.path.join(outputdir,testsetN)\n",
        "\n",
        "        cv2.imwrite(\"%s/%s_input.jpg\"%(outputdir_fin,testind),img)\n",
        "        cv2.imwrite(\"%s/%s_pred_T.jpg\"%(outputdir_fin,testind),np.uint8(output_image_t[0,:,:,0:3])) # output front scene (Transmission)\n",
        "        cv2.imwrite(\"%s/%s_pred_gR.jpg\"%(outputdir_fin,testind),np.uint8(output_image_rb4[0,:,:,0:3])) # output reflected back scene (Glass reflected reflection)\n",
        "        cv2.imwrite(\"%s/%s_pred_R.jpg\"%(outputdir_fin,testind),np.uint8(output_image_r[0,:,:,0:3])) # output back scene (Reflection)\n",
        "\n",
        "    # 'quality_assess_SM3' --> get the numerical numbers if transmission layers are available.----------\n",
        "    # Comment out the following code, if transmission_layers are not available.\n",
        "    #gtdir = '/content/drive/MyDrive/reflection-removal/test_imgs/transmission_layer'\n",
        "    #quality_assess_SM3(outputdir_fin, gtdir, '_pred_T', '')\n",
        "    # --------------------------------------------------------------------------------------------------\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA_VISIBLE_DEVICES 7\n",
            "is_training: 0\n",
            "[i] Loaded pre-trained vgg19 parameters\n",
            "[i] Hypercolumn ON, building hypercolumn features ... \n",
            "[i] Reconnet: Hypercolumn ON, building hypercolumn features ... \n",
            "task /content/drive/MyDrive/reflection-removal/pre-trained.tar/pre-trained\n",
            "Separation net loaded/content/drive/MyDrive/reflection-removal/pre-trained.tar/pre-trained/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/reflection-removal/pre-trained.tar/pre-trained/model.ckpt\n",
            "The testing part is executing\n",
            "Test time 18.896 for image /content/drive/MyDrive/Prism-test/12-4.jpg\n",
            "Test time 20.625 for image /content/drive/MyDrive/Prism-test/34_M.jpg\n",
            "Test time 25.896 for image /content/drive/MyDrive/Prism-test/104_M.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgnXQalAXtO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}